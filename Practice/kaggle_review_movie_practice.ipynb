{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAsaOGGx75Sf",
        "outputId": "595a4ee1-5f48-4be8-a551-fd93585ae689"
      },
      "source": [
        "pip install tika"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tika in /usr/local/lib/python3.7/dist-packages (1.24)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tika) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tika) (54.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (2020.12.5)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/aa/4ef5aa67a9a62505db124a5cb5262332d1d4153462eb8fd89c9fa41e5d92/urllib3-1.25.11-py2.py3-none-any.whl (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 11.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (3.0.4)\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: urllib3\n",
            "  Found existing installation: urllib3 1.26.3\n",
            "    Uninstalling urllib3-1.26.3:\n",
            "      Successfully uninstalled urllib3-1.26.3\n",
            "Successfully installed urllib3-1.25.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qU4vSIMb7_VT",
        "outputId": "bac8fce5-ba06-49ed-d61d-d2b4ae58299d"
      },
      "source": [
        "pip install boto3"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (1.17.27)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from boto3) (0.3.4)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.27 in /usr/local/lib/python3.7/dist-packages (from boto3) (1.20.27)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.27->boto3) (2.8.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.27->boto3) (1.25.11)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.27->boto3) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtQyMYRA7pOj"
      },
      "source": [
        "from bs4 import BeautifulSoup\r\n",
        "from tika import parser\r\n",
        "import urllib.request\r\n",
        "import datetime\r\n",
        "import requests\r\n",
        "import boto3\r\n",
        "\r\n",
        "# AWS 인증 상수\r\n",
        "AWS_ACCESS_KEY_ID = 'AKIA5XJJ3SGH4SKRGJNP'\r\n",
        "AWS_SECRET_ACCESS_KEY = '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'\r\n",
        "\r\n",
        "# 텍스트 파일 업로드 위해 s3 리소스 사용\r\n",
        "s3 = boto3.resource(\r\n",
        "    's3',\r\n",
        "    aws_access_key_id=AWS_ACCESS_KEY_ID,\r\n",
        "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY\r\n",
        ")\r\n",
        "\r\n",
        "\r\n",
        "def extract_target():\r\n",
        "    \"\"\"\r\n",
        "    추출 대상이 되는 타겟 리포트 목록 추출\r\n",
        "    :return:\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    # 추출 일자를 현재일로 부터 일주일 이전을 시작으로 현재일자 까지를 추출 범위로 선택\r\n",
        "    begin_date = datetime.datetime.now().date() + datetime.timedelta(days=-7)\r\n",
        "    end_date = datetime.datetime.now().date().isoformat()\r\n",
        "    extract_target_range_url = \"https://finance.naver.com/research/company_list.nhn?keyword=&brokerCode=&searchType=writeDate&writeFromDate={}&writeToDate={}&page={}\"\r\n",
        "\r\n",
        "    _target_list = list()\r\n",
        "    for idx in range(1, 30):\r\n",
        "        # 1 페이지부터 30페이지까지 하드코딩으로 돌립니다\r\n",
        "        # ToDo 페이지네이션 마지막 페이지까지 for문 돌도록 수정 필요 합니다 !\r\n",
        "        html = requests.get(extract_target_range_url.format(begin_date, end_date, idx))\r\n",
        "        soup = BeautifulSoup(html.text, 'html.parser')\r\n",
        "\r\n",
        "        table_class = soup.select('table.type_1')\r\n",
        "        trs = table_class[0].find_all('tr')\r\n",
        "\r\n",
        "        # 딕셔너리에 사명: pdf 다운로드 링크 맵핑하여 삽입\r\n",
        "        for tr_item in trs[2:-2]:\r\n",
        "            tds = tr_item.find_all('td')\r\n",
        "            if not tds[0].get('class'):\r\n",
        "                company_td = tds[0].text.strip()\r\n",
        "                file_path_td = tds[3].next.attrs.get('href')\r\n",
        "\r\n",
        "                target_elem = {\r\n",
        "                    'company': company_td,\r\n",
        "                    'filepath': file_path_td\r\n",
        "                }\r\n",
        "                _target_list.append(target_elem)\r\n",
        "\r\n",
        "    # 중복된 요소 제거 위함\r\n",
        "    # ToDo 시간 많이 걸린다면 해당 코드 리팩토링 부탁드립니다 :)\r\n",
        "    result_list = list({each_target['filepath']: each_target for each_target in _target_list}.values())\r\n",
        "    return result_list\r\n",
        "\r\n",
        "\r\n",
        "def download_file(download_url, filename):\r\n",
        "    \"\"\"\r\n",
        "    로컬에 pdf 파일 다운로드\r\n",
        "    :param download_url:\r\n",
        "    :param filename:\r\n",
        "    :return:\r\n",
        "    \"\"\"\r\n",
        "    # ToDo 다운로드 하지 않고 읽어올 수 있다면 해당 방법으로 변경 부탁드려요\r\n",
        "    response = urllib.request.urlopen(download_url)\r\n",
        "    file = open(filename + \".pdf\", 'wb')\r\n",
        "    file.write(response.read())\r\n",
        "    file.close()\r\n",
        "\r\n",
        "\r\n",
        "def pre_processing(content):\r\n",
        "    \"\"\"\r\n",
        "    데이터 전처리\r\n",
        "    :param content:\r\n",
        "    :return:\r\n",
        "    \"\"\"\r\n",
        "    # ToDo 전처리는 아예 안되어있습니다 ~!\r\n",
        "    return content.replace('\\n', '')\r\n",
        "\r\n",
        "\r\n",
        "target_list = extract_target()\r\n",
        "\r\n",
        "folder_name = 'emotion' + '/' + datetime.datetime.today().date().isoformat() + '_' + datetime.datetime.today().strftime(\"%A\")\r\n",
        "\r\n",
        "for item in target_list:\r\n",
        "    # ToDo .. 조금 더 깔끔하고 로지컬하게.. 부탁드려요 :( ㅎ\r\n",
        "    download_file(item.get('filepath'), item.get('company'))\r\n",
        "    parsed = parser.from_file(item.get('company') + \".pdf\")\r\n",
        "\r\n",
        "    upload_file_name = item.get('company') + '_result_' + '.txt'\r\n",
        "    txt = open(upload_file_name, 'w', encoding='utf-8')\r\n",
        "    # output.txt에 pdf파일 내용을 write\r\n",
        "    processed = pre_processing(parsed['content'])\r\n",
        "    print(processed, file=txt)  # ToDo 파일 with.. open 등의 쓰기 처리 방식 변경 확인 필\r\n",
        "    txt.close()\r\n",
        "    # txt 확장자 파일로 s3에 업로드 합니다.\r\n",
        "    s3.meta.client.upload_file(\r\n",
        "        upload_file_name,\r\n",
        "        'analysis-target-data',\r\n",
        "        folder_name + '/' + upload_file_name,\r\n",
        "        ExtraArgs={\r\n",
        "            'ACL': 'public-read'\r\n",
        "        }\r\n",
        "    )"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltNP3Wdx95Sf",
        "outputId": "74d07cde-c5f9-4959-a44d-5a486dfde31d"
      },
      "source": [
        "from google.colab import drive # 패키지 불러오기 \r\n",
        "from os.path import join  \r\n",
        "\r\n",
        "ROOT = \"/content/drive\"     # 드라이브 기본 경로\r\n",
        "print(ROOT)                 # print content of ROOT (Optional)\r\n",
        "drive.mount(ROOT)           # 드라이브 기본 경로 Mount"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un_9gI8X7xeW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ecb5e7d-4d9b-438b-a12b-70ad43bdd592"
      },
      "source": [
        "MY_GOOGLE_DRIVE_PATH = 'My Drive/Colab Notebooks/NLP/' # 프로젝트 경로\r\n",
        "PROJECT_PATH = join(ROOT, MY_GOOGLE_DRIVE_PATH) # 프로젝트 경로\r\n",
        "print(PROJECT_PATH)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/NLP/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNRyMN_DDN6I",
        "outputId": "3a7636be-f532-4090-af2e-0efffee65a54"
      },
      "source": [
        "%cd \"{PROJECT_PATH}\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/NLP\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "e1E35GMVDSUA",
        "outputId": "80bc4da8-aa27-440c-c932-0ee7794de799"
      },
      "source": [
        "import pandas as pd\r\n",
        "review_df = pd.read_csv(\"data/labeledTrainData.tsv\", header = 0, sep=\"\\t\", quoting = 3)\r\n",
        "review_df.head()\r\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"5814_8\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"With all this stuff going down at the moment ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"2381_9\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"7759_3\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"3630_4\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"It must be assumed that those who praised thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"9495_8\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  sentiment                                             review\n",
              "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
              "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
              "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
              "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
              "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a38fa4lZDWdC",
        "outputId": "31b6af1e-d8bc-46fa-fcd5-40b05098b4bf"
      },
      "source": [
        "review_df.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIB8Rs-jG675"
      },
      "source": [
        "import re\r\n",
        "\r\n",
        "# <br> html 태그는 replace 함수를 공백으로 변환\r\n",
        "review_df['review'] = review_df['review'].str.replace('<br />', ' ')\r\n",
        "\r\n",
        "# 파이썬의 정규 표현식 모듈인 re를 이용해 영어 문자열이 아닌 문자는 모두 공백으로 변환 \r\n",
        "review_df['review'] = review_df['review'].apply(lambda x : re.sub(\"[^a-zA-Z]\", \" \", x))\r\n",
        "\r\n",
        "#[^a-zA-Z]의 의미는 영어 대/소문자가 아닌 모든 문자를 찾는 것임"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2RbW19eHZKm",
        "outputId": "9b83f029-8925-4274-fe30-6e3485e4ffd5"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "class_Y = review_df['sentiment']\r\n",
        "feature_X = review_df.drop(['id', 'sentiment'], axis = 1, inplace=False)\r\n",
        "print(feature_X)\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(feature_X, class_Y, test_size = 0.3, random_state = 156)\r\n",
        "\r\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                  review\n",
            "0       With all this stuff going down at the moment ...\n",
            "1         The Classic War of the Worlds   by Timothy ...\n",
            "2       The film starts with a manager  Nicholas Bell...\n",
            "3       It must be assumed that those who praised thi...\n",
            "4       Superbly trashy and wondrously unpretentious ...\n",
            "...                                                  ...\n",
            "24995   It seems like more consideration has gone int...\n",
            "24996   I don t believe they made this film  Complete...\n",
            "24997   Guy is a loser  Can t get girls  needs to bui...\n",
            "24998   This    minute documentary Bu uel made in the...\n",
            "24999   I saw this movie as a child and it broke my h...\n",
            "\n",
            "[25000 rows x 1 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((17500, 1), (7500, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tvBlWQOHc7a"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0jlSvJMLhAW",
        "outputId": "57527667-1131-4d35-843f-4e9e341f7bae"
      },
      "source": [
        "# 스톱 워드는 English, Filtering, Ngram은 (1, 2)로 설정하여 CountVectorization 수행\r\n",
        "# LogisticRegression의 C는 10으로 설정\r\n",
        "pipeline = Pipeline([\r\n",
        "                     ('cnt_vect', CountVectorizer(stop_words = 'english', ngram_range=(1, 2))), \r\n",
        "                     ('lr_clf', LogisticRegression(C=10))])\r\n",
        "\r\n",
        "# Pipeline 객체를 이용해 fit(), predict()로 학습/예측 수행, predict_proba()는 roc_auc 때문에 수행. \r\n",
        "pipeline.fit(X_train['review'], y_train)\r\n",
        "pred = pipeline.predict(X_test['review'])\r\n",
        "pred_probs = pipeline.predict_proba(X_test['review'])[:, 1]\r\n",
        "\r\n",
        "print('예측 정확도는 {0:.4f}, ROC-AUC는 {1:.4f}'.format(accuracy_score(y_test, pred), roc_auc_score(y_test, pred_probs)))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "예측 정확도는 0.8860, ROC-AUC는 0.9503\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZNlggciKhJW"
      },
      "source": [
        "from xgboost import XGBClassifier\r\n",
        "\r\n",
        "pipeline1 = Pipeline([\r\n",
        "                     ('cnt_vect', CountVectorizer(stop_words = 'english', ngram_range=(1, 2))), \r\n",
        "                     ('lr_clf', XGBClassifier())])\r\n",
        "\r\n",
        "# Pipeline 객체를 이용해 fit(),\r\n",
        "# predict()로 학습/예측 수행, \r\n",
        "# predict_proba()는 roc_auc 때문에 수행. \r\n",
        "pipeline1.fit(X_train['review'], y_train)\r\n",
        "pred = pipeline1.predict(X_test['review'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOUkPUFAMSS0",
        "outputId": "7c26532a-4d6f-44fa-ccba-84b063793ea8"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\r\n",
        "print('검증 정확도: ', accuracy_score(y_test, pred))\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "\r\n",
        "print(classification_report(pred, y_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "검증 정확도:  0.8088\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.84      0.79      3264\n",
            "           1       0.87      0.78      0.82      4236\n",
            "\n",
            "    accuracy                           0.81      7500\n",
            "   macro avg       0.81      0.81      0.81      7500\n",
            "weighted avg       0.82      0.81      0.81      7500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piQbFhz2NR7H",
        "outputId": "748a6389-137a-4057-a1da-c7d98538e32e"
      },
      "source": [
        "!pip install eli5"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting eli5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/54/04cab6e1c0ae535bec93f795d8403fdf6caf66fa5a6512263202dbb14ea6/eli5-0.11.0-py2.py3-none-any.whl (106kB)\n",
            "\r\u001b[K     |███                             | 10kB 13.4MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 20kB 19.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 30kB 23.6MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 40kB 21.1MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 51kB 18.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 61kB 20.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 71kB 10.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 81kB 11.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 92kB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 102kB 11.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 11.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from eli5) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from eli5) (0.22.2.post1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from eli5) (2.11.3)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from eli5) (0.8.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from eli5) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from eli5) (1.4.1)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.7/dist-packages (from eli5) (20.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->eli5) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->eli5) (1.1.1)\n",
            "Installing collected packages: eli5\n",
            "Successfully installed eli5-0.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrU79UOPOKaw"
      },
      "source": [
        "import warnings\r\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\r\n",
        "\r\n",
        "import eli5\r\n",
        "from eli5.sklearn import PermutationImportance"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o75uluzOoUS"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "plt.rcParams['figure.dpi'] = 144"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBl-L8nJOt89"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}